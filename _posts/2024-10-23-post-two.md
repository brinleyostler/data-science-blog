---
layout: post
title:  "AZ's Most Popular Books: Web-Scraping in Action"
date: 2024-10-23
description: Using XPath in Selenium to scrape data from a local website.   
image: "/assets/img/image5.jpg"
---
<p class="intro"><span class="dropcap">M</span>y favorite thing to do is write my stats blog. But when I'm not writing my blog, I like to read.</p>

#### Project Motivation

In this project, I set out to analyze a dataset of the top books (and audiobooks) from my local library. My goal was to uncover patterns with the most popular titles, authors, and formats. 
* Which books are most popular?
* Are most books currently available or wait-list only?
* Does a book's popularity (ranking) relate to the total number of copies?
* What is the average wait time for each book type?
* Which author has the most books on the popularity list?

To answer these questions, I used web-scraping techniques in Python, specifically leveraging Selenium and XPath, to gather this data from my hometown library’s digital database.


#### Quick note on webscraping practices:

Whenever we as data scientists want to scrape data from the web, we have to ensure we are following best practice. Check that site's robots.txt file (accessible at the base url/robots.txt). Good scraping practice ensures we are using delay functions in our, only scraping necessary data, and not accessing sensitive or restricted information.
Before starting, I verified that the library's terms of service allowed for this type of data collection, ensuring that I followed any restrictions on data usage.


## Data Collection Process

Here's a summary of the main steps I followed for my data collection. For a full document of my code, check out by GitHub [best-selling-books](https://github.com/brinleyostler/best-selling-books) repository.

1. Set up the Selenium environment
When using Selenium, you can use it with practically any sort of web driver. My default browser is Google Chrome, so I set up my environment with the Chrome WebDriver. You can look into more driver options [here](https://www.selenium.dev/documentation/webdriver/drivers/options/).

I chose to use Selenium so I could scrape data beyond the first page. Thus, I needed to use XPath to advance to the next screen by clicking the 'next page' button at the bottom of the page. There may be other ways to di this, but I found this method the most straightforward for this project.


2. Scraping the Main Websites
I ultimately wanted to scrape the entire dataset, but there were a lot of pages (over 42!), and it would have taken a much longer time to scrape, especially with the time delay I included in my code. So, I chose to only scrape the first 10 pages of both the top [ebooks](https://phoenix.overdrive.com/collection/25972?page=1&sortBy=mostpopular-site&maxItems=1000&mediaTypes=ebook) and the top [audioboks](https://phoenix.overdrive.com/collection/25978) in the database. This resulted in a total of the most popular 480 books (240 of each book type).

Using a while loop, I navigated through the first ten pages of the ebooks and audiobooks sections on the library’s site. I extracted the titles, authors, availability status, format, link, and rank for each item. 


3. Scraping the Individual Books' Sites
I wanted more information on each individual book, so I constructed another while loop to iterate through the links I had just collected. In this loop, I then gathered the number of copies, ratings, and wait times. 

This is the process that takes the longest. There are options you can employ to avoid opening the web driver in a window and allow it to operate faster. However, I wanted to monitor my code as it ran, so my code will reflect that.


4. Cleaning and Assembling the DataFrame
Once all the data had been collected, there were a few things I wanted to clean up and add to my dataset. I made sure all the types were appropriate for the dataset:
* I checked the types of each of my columns and made sure they were appropriate (type float or type int for my numeric columns and type str for my categorical columns).
* At this point, I created a Pandas dataframe with the Rank, Title, Author, Rating, Format, Copies, Availability, and Wait Time.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rank</th>
      <th>Title</th>
      <th>Author</th>
      <th>Rating</th>
      <th>Format</th>
      <th>Copies</th>
      <th>Availability</th>
      <th>Wait Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>The Women</td>
      <td>Kristin Hannah</td>
      <td>4.4</td>
      <td>EBOOK</td>
      <td>25.0</td>
      <td>WAIT LIST</td>
      <td>6 months</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Five Total Strangers</td>
      <td>Natalie D. Richards</td>
      <td>3.5</td>
      <td>EBOOK</td>
      <td>12.0</td>
      <td>AVAILABLE</td>
      <td>No wait</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>It Ends With Us</td>
      <td>Colleen Hoover</td>
      <td>4.3</td>
      <td>EBOOK</td>
      <td>15.0</td>
      <td>WAIT LIST</td>
      <td>6 months</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Funny Story</td>
      <td>Emily Henry</td>
      <td>4.2</td>
      <td>EBOOK</td>
      <td>18.0</td>
      <td>WAIT LIST</td>
      <td>6 months</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iron Flame</td>
      <td>Rebecca Yarros</td>
      <td>4.2</td>
      <td>EBOOK</td>
      <td>18.0</td>
      <td>WAIT LIST</td>
      <td>23 weeks</td>
    </tr>
  </tbody>
</table>
</div>


* I then created a new column that calculated the number of weeks of wait time. This included converting 'No wait' entries to 0, and converting the 'months' entries to weeks by removing the text and multiplying them by 4.
*I chose to multiply by 4 because I saw that after '23 weeks', the wait time would automatically switch to 6 months. This told me that 6 months would be 6 \* 4 = 24 weeks.* I had to make sure that these data points were of type float.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rank</th>
      <th>Title</th>
      <th>Author</th>
      <th>Rating</th>
      <th>Format</th>
      <th>Copies</th>
      <th>Availability</th>
      <th>Wait Time</th>
      <th>Wait Weeks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>The Women</td>
      <td>Kristin Hannah</td>
      <td>4.4</td>
      <td>EBOOK</td>
      <td>25.0</td>
      <td>WAIT LIST</td>
      <td>6 months</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Five Total Strangers</td>
      <td>Natalie D. Richards</td>
      <td>3.5</td>
      <td>EBOOK</td>
      <td>12.0</td>
      <td>AVAILABLE</td>
      <td>No wait</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>It Ends With Us</td>
      <td>Colleen Hoover</td>
      <td>4.3</td>
      <td>EBOOK</td>
      <td>15.0</td>
      <td>WAIT LIST</td>
      <td>6 months</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Funny Story</td>
      <td>Emily Henry</td>
      <td>4.2</td>
      <td>EBOOK</td>
      <td>18.0</td>
      <td>WAIT LIST</td>
      <td>6 months</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iron Flame</td>
      <td>Rebecca Yarros</td>
      <td>4.2</td>
      <td>EBOOK</td>
      <td>18.0</td>
      <td>WAIT LIST</td>
      <td>23 weeks</td>
      <td>23.0</td>
    </tr>
  </tbody>
</table>
</div>

